# 杨逸飞QandA项目分析报告

> **分析日期**: 2026-01-28  
> **项目路径**: ~/projects/QandA/  
> **项目大小**: 185MB  
> **分析目的**: 了解项目规模、API使用情况

---

## 一、项目规模分析

### 1.1 总体情况

```
总大小: 185MB
主要组成:
- PDF文件: 137MB (74%)
- 代码和数据: 48MB (26%)
```

### 1.2 空间占用详细分析

| 目录 | 大小 | 占比 | 内容说明 |
|------|------|------|---------|
| `utility/data/papers/pdf/` | ~99MB | 53% | **论文PDF文件** (约27篇) |
| `data/others/pdf/` | ~38MB | 21% | **其他PDF文件** (3篇大文件) |
| `data/` | 52MB | 28% | 知识图谱数据、处理结果 |
| `output/` | 27MB | 15% | 输出结果 |
| `lib/` | 756KB | <1% | 可视化库 |
| 其他代码 | ~2MB | 1% | Python源码、配置文件 |

### 1.3 PDF文件统计

**总共29个PDF文件**，分布在两个目录：

#### utility/data/papers/pdf/ (26个PDF)
```
paper_14.pdf    19MB  ⬅️ 最大
paper_15.pdf    16MB
paper_22.pdf    8.9MB
paper_10.pdf    7.3MB
paper_17.pdf    5.7MB
paper_21.pdf    5.1MB
paper_6.pdf     4.2MB
paper_5.pdf     3.4MB
... (其余18个文件)
```

#### data/others/pdf/ (3个PDF)
```
paper_1598493694083731977.pdf    30MB  ⬅️ 单个最大文件
paper_1548143366972899485.pdf    4.8MB
paper_1500506958513111224.pdf    3.2MB
```

### 1.4 结论：为什么这么大？

**答案: 是的，论文PDF在里面**

- ✅ 主要原因是**29篇学术论文的PDF文件**占用了137MB
- ✅ 这些PDF是**研究数据集**，用于构建学术知识图谱
- ✅ 项目需要从这些PDF中提取信息（作者、机构、引用关系等）
- ✅ 如果删除所有PDF，项目大小会降至约48MB

---

## 二、API Key分析

### 2.1 API配置文件位置

**主要配置文件**: `utility/.env`

```bash
OPENAI_API_KEY="sk-D3Tyugy01k9y5kFtA2v6wavTFnrCt9erzGdyntECzAZAoXpb"
OPENAI_BASE_URL="https://www.dmxapi.com/v1"
SERPAPI_KEY="474ee1d011d9e71526e09af93859e755c98ba2b190e8e4c0b36d828560f0fcc9"
```

### 2.2 API类型分析

#### 🔑 OpenAI API Key

**Key格式**: `sk-D3Tyugy01k9y5kFtA2v6wavTFnrCt9erzGdyntECzAZAoXpb`

**判断依据**:
1. ✅ Key以`sk-`开头，符合OpenAI格式
2. ✅ Base URL是`https://www.dmxapi.com/v1` - 这是**第三方API代理/转发服务**
3. ✅ 不是OpenAI官方的`https://api.openai.com/v1`

**结论**: 
- **这是通过第三方代理访问的OpenAI API**
- dmxapi.com是一个API转发/代理服务商
- 可能是为了：
  - 绕过地区限制
  - 批量购买降低成本
  - 统一管理多个API Key

#### 🔍 SerpAPI Key

**Key**: `474ee1d011d9e71526e09af93859e755c98ba2b190e8e4c0b36d828560f0fcc9`

**用途**: SerpAPI是一个**搜索引擎结果API服务**
- 提供Google、Bing等搜索引擎的结果
- 用于知识图谱扩展时进行网络搜索
- 在`utility/kg_expansion/`模块中使用

### 2.3 API使用场景

#### 场景1: 实体提取 (utility/generate_entities.py)

**使用的模型**: `deepseek-v3.2-exp`

```python
DEFAULT_MODEL = "deepseek-v3.2-exp"

client = AsyncOpenAI(api_key=api_key)

response = await client.chat.completions.create(
    model=self.model,  # deepseek-v3.2-exp
    messages=[...]
)
```

**重要发现**:
- ✅ 虽然代码中导入的是`openai`库
- ✅ 但实际使用的模型是**DeepSeek V3**（中国的大模型）
- ✅ 这是因为Base URL指向`dmxapi.com`，这个代理服务支持多种模型
- ✅ OpenAI的Python SDK可以通过修改Base URL调用其他兼容的API

#### 场景2: 论文分块 (utility/subsection.py)

```python
def chunk_paper_with_llm(client: OpenAI, paper_content: str, model: str = "gpt-4") -> dict:
```

**默认模型**: `gpt-4`（可配置）

#### 场景3: 问答生成 (utility/QandA_generation/)

```python
response = client.chat.completions.create(
    model=model,  # 从配置传入
    messages=[...]
)
```

#### 场景4: 知识图谱扩展 (utility/kg_expansion/)

```python
class LLMConfig:
    def __init__(self, api_key: str, base_url: str = "https://api.openai.com/v1",
                 model: str = "gpt-4", ...):
```

**默认模型**: `gpt-4`（可配置）

### 2.4 API用途总结

**这个API Key是用于什么的？**

✅ **普通的大模型应用** - 用于研究项目，不是AI编程工具

具体用途：
1. **从论文中提取实体**（材料、方法、参数、结果）
2. **论文内容分块和结构化**
3. **生成复杂推理问答题**
4. **知识图谱扩展和补全**
5. **实体消歧和关系抽取**

**不是用于**:
- ❌ 不是Codebuddy这类AI编程助手
- ❌ 不是代码生成工具
- ❌ 不是GitHub Copilot类的编码助手

### 2.5 实际使用的模型

| 模块 | 默认模型 | 可配置? | 用途 |
|------|---------|--------|------|
| `generate_entities.py` | **deepseek-v3.2-exp** | ✅ | 实体提取 |
| `subsection.py` | `gpt-4` | ✅ | 论文分块 |
| `QandA_generation/` | 未指定 | ✅ | 问答生成 |
| `kg_expansion/` | `gpt-4` | ✅ | 图谱扩展 |

**关键发现**:
- 实体提取模块明确使用**DeepSeek V3**
- 其他模块默认`gpt-4`，但可以通过配置修改
- 通过dmxapi代理，可以灵活切换不同模型

---

## 三、项目架构概览

### 3.1 项目简介

**项目名称**: 学术知识图谱系统（Academic Knowledge Graph System）

**核心功能**:
1. 构建学术论文知识图谱（Paper → Author → Institution → Venue）
2. 从PDF中提取实体和关系
3. 生成基于图谱的复杂推理问答题
4. 图谱可视化

### 3.2 目录结构

```
~/projects/QandA/
├── academic_kg/              # 核心图谱模块
│   ├── graph.py             # 图谱类
│   ├── nodes.py             # 节点定义
│   ├── edges.py             # 边定义
│   ├── qa_generator.py      # 问答生成器
│   └── visualizer.py        # 可视化
│
├── utility/                  # 工具模块
│   ├── data/papers/pdf/     # 论文PDF数据集 (99MB)
│   ├── generate_entities.py # 实体提取（DeepSeek）
│   ├── subsection.py        # 论文分块
│   ├── kg_expansion/        # 图谱扩展
│   ├── QandA_generation/    # 问答生成
│   └── .env                 # API配置 ⚠️
│
├── data/                     # 数据文件
│   ├── raw/                 # 原始数据
│   ├── processed/           # 处理后的数据
│   ├── papers/              # 论文元数据
│   └── others/pdf/          # 其他PDF (38MB)
│
├── output/                   # 输出结果
│   ├── visualization.png    # 图谱可视化
│   └── QandA/               # 生成的问答对
│
├── lib/                      # 第三方库
│   └── vis-9.1.2/           # 网络可视化
│
├── example.py               # 使用示例
├── main.py                  # 主程序
└── README.md                # 项目文档
```

### 3.3 数据流

```
PDF论文 (137MB)
    ↓
[generate_entities.py] ← DeepSeek API
    ↓
知识图谱 (nodes + edges)
    ↓
[QandA_generation/] ← GPT-4 API
    ↓
复杂推理问答题
```

### 3.4 与胡云舒项目的关系

**胡云舒的项目** (`browsecomp-V2`):
- 作用: **提供约束→图操作的映射规则**
- 输出: 30条规则的JSON映射表

**杨逸飞的项目** (`QandA`):
- 作用: **完整的知识图谱系统和问答生成引擎**
- 输入: 论文PDF
- 输出: 问答题

**集成关系**:
```
杨逸飞的系统
    ↓
提取约束条件
    ↓
调用胡云舒的映射表 ← constraint_to_graph_mapping.json
    ↓
获取图操作指令
    ↓
在知识图谱上执行查询
    ↓
生成答案
```

---

## 四、成本和性能估算

### 4.1 数据集规模

- **论文数量**: 29篇PDF
- **总页数**: 约200-300页（估算）
- **知识图谱规模**: 
  - 节点: 数千个（Paper, Author, Institution, Entity）
  - 边: 数万个（HAS_AUTHOR, MENTIONS等）

### 4.2 API调用量估算

#### 实体提取阶段

**每篇论文**:
- 摘要提取: 1次API调用
- 正文分块: 假设分成10个chunks = 10次API调用
- **小计**: 11次调用/篇

**29篇论文总计**:
- 约 **319次API调用**

#### 问答生成阶段

**假设生成100道题**:
- 每道题1次API调用
- **小计**: 100次调用

#### 总计
- **约420次API调用**（一次完整处理）

### 4.3 成本估算（粗略）

假设使用DeepSeek V3（相对便宜）:
- 输入: $0.27/百万tokens
- 输出: $1.1/百万tokens

**每次处理约29篇论文**:
- 实体提取: 约319次 × 2000 tokens = 约64万tokens
- 问答生成: 约100次 × 1500 tokens = 约15万tokens
- **估算成本**: $0.5-1 USD（非常粗略）

**如果使用GPT-4**:
- 成本会高10-20倍
- 约 $10-20 USD/次

---

## 五、安全建议

### 5.1 ⚠️ API Key暴露风险

**当前状态**: 
- ✅ API Key在`.env`文件中
- ⚠️ 但代码中有硬编码的Key（多个文件）

**建议**:
1. 将所有硬编码的Key移除
2. 统一使用环境变量
3. 将`.env`加入`.gitignore`
4. 如果已经推送到GitHub，立即轮换Key

### 5.2 发现的硬编码Key位置

```bash
utility/main_pipline.py:    API_KEY = "sk-D3Tyugy..."
utility/subsection.py:    API_KEY = "sk-D3Tyugy..."
utility/expand_kg_example.py:    METHOD1_API_KEY = "sk-D3Tyugy..."
utility/QandA_generation/generate_reasoning_questions.py:    API_KEY = "sk-D3Tyugy..."
```

**建议修改**:
```python
# 不要这样 ❌
API_KEY = "sk-D3Tyugy..."

# 应该这样 ✅
import os
from dotenv import load_dotenv
load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")
```

---

## 六、项目优缺点分析

### 6.1 优点

✅ **功能完整**: 从PDF到问答题的完整pipeline  
✅ **模块化设计**: 代码结构清晰，易于维护  
✅ **模型灵活**: 支持切换不同的LLM模型  
✅ **成本优化**: 使用DeepSeek等更便宜的模型  
✅ **可视化**: 提供图谱可视化功能  

### 6.2 缺点/改进空间

⚠️ **PDF占用大**: 137MB的PDF可以考虑外部存储  
⚠️ **API Key安全**: 有硬编码情况，需要清理  
⚠️ **文档不完整**: 部分模块缺少详细文档  
⚠️ **测试覆盖**: 单元测试较少  

---

## 七、总结

### 问题1: 为什么这么大（180MB）？

**答案**: 
- ✅ 主要是**29篇学术论文PDF**（137MB）
- ✅ 这些PDF是项目的**研究数据集**
- ✅ 用于构建知识图谱和测试系统
- ✅ 代码本身只有约2MB

### 问题2: API Key是什么？

**答案**:
- ✅ 是**OpenAI兼容的API Key**
- ✅ 通过**第三方代理dmxapi.com**访问
- ✅ 主要使用**DeepSeek V3**模型（中国大模型）
- ✅ 用于**普通的大模型应用**（实体提取、问答生成）
- ❌ **不是AI编程工具**的Key

**详细说明**:
- 虽然代码用的是`openai`库
- 但通过修改Base URL实现了对DeepSeek等模型的调用
- 这是常见的做法，因为很多模型提供OpenAI兼容的API
- dmxapi.com是一个API代理/转发服务

---

## 八、建议的后续行动

### 8.1 立即行动（安全相关）

1. **检查GitHub仓库**: 确认API Key是否已提交
2. **轮换Key**: 如果已泄露，立即更换
3. **清理硬编码**: 移除所有硬编码的API Key
4. **更新.gitignore**: 确保`.env`不会被提交

### 8.2 优化建议（性能/成本）

1. **外部存储PDF**: 考虑将PDF放在对象存储（如OSS）
2. **缓存提取结果**: 避免重复提取同一篇论文
3. **批量处理**: 优化API调用，减少成本
4. **监控用量**: 添加API用量监控和告警

### 8.3 协作建议（与胡云舒）

1. **接口对接**: 确认映射表的使用方式
2. **测试集成**: 用实际数据测试完整流程
3. **文档完善**: 补充集成文档和示例
4. **定期同步**: 建立定期沟通机制

---

**报告生成时间**: 2026-01-28  
**分析者**: Codebuddy Code  
**项目所有者**: 杨逸飞  

**如有问题，请联系项目组成员讨论。**
